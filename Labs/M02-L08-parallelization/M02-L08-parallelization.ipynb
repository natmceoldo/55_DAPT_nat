{"nbformat":4,"nbformat_minor":2,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3.9.2 64-bit"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.2"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"colab":{"name":"main.ipynb","provenance":[],"collapsed_sections":[]},"interpreter":{"hash":"ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"}},"cells":[{"cell_type":"markdown","source":["![Ironhack logo](https://i.imgur.com/1QgrNNw.png)\r\n","\r\n","# Lab | Parallelization\r\n","\r\n","## Introduction\r\n","\r\n","This lab will combine parallelization with some of the other topics you have learned in the Intermediate Python module of this program (list comprehensions, requests library, functional programming, web scraping, etc.). You will write code that extracts a list of links from a web page, requests each URL, and then indexes the page referenced by each link - both sequentially and in parallel.\r\n","\r\n","## Resources\r\n","\r\n","- [Multiprocessing Library Documentation](https://docs.python.org/3/library/multiprocessing.html?highlight=multiprocessing#module-multiprocessing)\r\n","- [Python Parallel Computing (in 60 Seconds or less)](https://dbader.org/blog/python-parallel-computing-in-60-seconds)\r\n","- [Python Multiprocessing: Pool vs Process â€“ Comparative Analysis](https://www.ellicium.com/python-multiprocessing-pool-process/)"],"metadata":{}},{"cell_type":"markdown","source":["## Step 1: Use the requests library to retrieve the content from the URL below."],"metadata":{}},{"cell_type":"code","execution_count":6,"source":["import requests\r\n","url = 'https://en.wikipedia.org/wiki/Data_science'"],"outputs":[],"metadata":{"id":"HlQZvSUqSEjn","colab_type":"code","colab":{}}},{"cell_type":"code","execution_count":8,"source":["# your code here"],"outputs":[],"metadata":{"id":"dHlgfatrSEjs","colab_type":"code","colab":{}}},{"cell_type":"markdown","source":["## Step 2: Use BeautifulSoup to extract a list of all the unique links on the page."],"metadata":{"id":"Ig5G0TTDSEjw","colab_type":"text"}},{"cell_type":"markdown","source":[],"metadata":{}},{"cell_type":"code","execution_count":9,"source":["from bs4 import BeautifulSoup"],"outputs":[],"metadata":{"id":"zahpf2s-SEjx","colab_type":"code","colab":{}}},{"cell_type":"code","execution_count":18,"source":["# your code here"],"outputs":[],"metadata":{"scrolled":true,"id":"VfmrZsypSEj0","colab_type":"code","colab":{}}},{"cell_type":"markdown","source":["## Step 3: Use list comprehensions with conditions to clean the link list.\r\n","\r\n","Create a list with the absolute link and remove any that contain a percentage sign (%)"],"metadata":{"id":"i7TXSNXCSEj3","colab_type":"text"}},{"cell_type":"code","execution_count":null,"source":["# your code here"],"outputs":[],"metadata":{"id":"mHDkpTrISEj7","colab_type":"code","colab":{}}},{"cell_type":"markdown","source":["## Step 4: Write a function called crawl_page that accepts a link and does the following.\r\n","\r\n","- Request the content of the page referenced by that link.\r\n","- Create a soup with the request content.\r\n","- Extract a list of links\r\n","- Return the count of links in the page"],"metadata":{"id":"liPZ-FYLSEkA","colab_type":"text"}},{"cell_type":"code","execution_count":null,"source":["# your code here"],"outputs":[],"metadata":{"id":"jErdx2cdSEkD","colab_type":"code","colab":{}}},{"cell_type":"markdown","source":["## Step 5: Sequentially loop through the list of links, running the crawl_page function each time and save result in a list.\r\n","\r\n","Remember to include `%%time` at the beginning of the cell so that it measures the time it takes for the cell to run."],"metadata":{"id":"qyDm2n-rSEkG","colab_type":"text"}},{"cell_type":"code","execution_count":null,"source":["# your code here"],"outputs":[],"metadata":{"id":"Mm7-pzw4SEkK","colab_type":"code","colab":{}}},{"cell_type":"markdown","source":["## Step 6: Sequentially loop through the list of links, running the index_page function each time.\r\n","\r\n","Remember to include `%%time` at the beginning of the cell so that it measures the time it takes for the cell to run."],"metadata":{"id":"VVDNEdyVSEkM","colab_type":"text"}},{"cell_type":"code","execution_count":null,"source":["#import multiprocessing\r\n","import multiprocess\r\n","# If you are using MaC use the multiprocessing library "],"outputs":[],"metadata":{"id":"1akpUc5_SEkN","colab_type":"code","colab":{}}},{"cell_type":"code","execution_count":null,"source":["# your code here"],"outputs":[],"metadata":{}}]}